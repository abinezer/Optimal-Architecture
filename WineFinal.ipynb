{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"archive/winequality-red.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed acidity',\n",
       " 'volatile acidity',\n",
       " 'citric acid',\n",
       " 'residual sugar',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'total sulfur dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_cols = list(df.columns)[:-1]\n",
    "input_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cols = ['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_arrays(df):\n",
    "    # Make a copy of the original dataframe\n",
    "    df1 = df.copy(deep=True)\n",
    "    # Extract input & outupts as numpy arrays\n",
    "    inputs_array = df1[input_cols].to_numpy()\n",
    "    targets_array = df1[output_cols].to_numpy()\n",
    "    return inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 7.4  ,  0.7  ,  0.   , ...,  3.51 ,  0.56 ,  9.4  ],\n",
       "        [ 7.8  ,  0.88 ,  0.   , ...,  3.2  ,  0.68 ,  9.8  ],\n",
       "        [ 7.8  ,  0.76 ,  0.04 , ...,  3.26 ,  0.65 ,  9.8  ],\n",
       "        ...,\n",
       "        [ 6.3  ,  0.51 ,  0.13 , ...,  3.42 ,  0.75 , 11.   ],\n",
       "        [ 5.9  ,  0.645,  0.12 , ...,  3.57 ,  0.71 , 10.2  ],\n",
       "        [ 6.   ,  0.31 ,  0.47 , ...,  3.39 ,  0.66 , 11.   ]]),\n",
       " array([[5],\n",
       "        [5],\n",
       "        [5],\n",
       "        ...,\n",
       "        [6],\n",
       "        [5],\n",
       "        [6]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_array, targets_array = dataframe_to_arrays(df)\n",
    "inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1599, 11), (1599, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_array.shape,targets_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "inputs = torch.Tensor(inputs_array)\n",
    "targets = torch.Tensor(targets_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "dataset = TensorDataset(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = len(df)\n",
    "val_percent = 0.8 # between 0.1 and 0.2\n",
    "val_size = int(num_rows * val_percent)\n",
    "train_size = num_rows - val_size\n",
    "\n",
    "\n",
    "train_df, val_df = random_split(dataset, [train_size, val_size]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_df, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_df, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(input_cols)\n",
    "output_size = len(output_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class WineModel(nn.Module):\n",
    "    def __init__(self,number_of_neurons):\n",
    "        super().__init__()     \n",
    "        self.fc1 = nn.Linear(input_size, number_of_neurons)\n",
    "        self.fc2 = nn.Linear(number_of_neurons,output_size)\n",
    "        # fill this (hint: use input_size & output_size defined above)\n",
    "        #model initialized with random weight\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = F.relu(self.fc1(xb))\n",
    "        out = self.fc2(xb)             # batch wise forwarding\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch \n",
    "        # Generate predictions\n",
    "        out = self(inputs)         \n",
    "        # Calcuate loss\n",
    "        loss = F.l1_loss(out, targets)  # batch wise training step and loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        # Generate predictions\n",
    "        out = self(inputs)\n",
    "        # Calculate loss\n",
    "        loss =F.l1_loss(out, targets)       # batch wise validation and loss    \n",
    "        return {'val_loss': loss.detach()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine val losses of all batches as average\n",
    "        return {'val_loss': epoch_loss.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result, num_epochs):\n",
    "        # Print result every 20th epoch\n",
    "        if (epoch+1) % 100 == 0 or epoch == num_epochs-1:\n",
    "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  WineModel(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.2874, -0.0383, -0.0042,  0.2060,  0.1300, -0.0648, -0.0745,  0.2712,\n",
       "           0.0153,  0.0749, -0.2624],\n",
       "         [ 0.0439, -0.0306, -0.2312,  0.2429,  0.1919, -0.0710, -0.1451,  0.1855,\n",
       "          -0.2631, -0.1902,  0.2098],\n",
       "         [-0.0285,  0.1400, -0.1070, -0.2132,  0.0404,  0.0567, -0.2198,  0.0546,\n",
       "           0.2085, -0.2122,  0.2572],\n",
       "         [ 0.1936, -0.2660, -0.0611,  0.2424, -0.2894, -0.0890,  0.2124, -0.2759,\n",
       "          -0.1737,  0.0109,  0.1348]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2339,  0.1758,  0.3002,  0.0858], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.4699,  0.0852,  0.1270,  0.2512]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.4468], requires_grad=True)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result, epochs)\n",
    "        history.append(result)  #appends total validation loss of whole validation set epoch wise\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 2.7276391983032227}\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(model,val_loader) # Use the the evaluate function\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7276391983032227"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs = 1000\n",
    "#lr = 1e-2\n",
    "#history1 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs = 1000\n",
    "#lr = 1e-3\n",
    "#history2 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 2.7276391983032227}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = evaluate(model,val_loader)\n",
    "val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(input, target, model):\n",
    "    inputs = input.unsqueeze(0) \n",
    "    predictions = model(inputs)\n",
    "    prediction = predictions[0].detach()\n",
    "    print(\"Input:\", input)\n",
    "    print(\"Target:\", target)\n",
    "    print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([ 9.0000,  0.5300,  0.4900,  1.9000,  0.1710,  6.0000, 25.0000,  0.9975,\n",
      "         3.2700,  0.6100,  9.4000])\n",
      "Target: tensor([6.])\n",
      "Prediction: tensor([2.2748])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_df[0]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([ 7.9000,  0.7650,  0.0000,  2.0000,  0.0840,  9.0000, 22.0000,  0.9962,\n",
      "         3.3300,  0.6800, 10.9000])\n",
      "Target: tensor([6.])\n",
      "Prediction: tensor([2.0468])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_df[10]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input, target = val_df[5]\n",
    "#predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self,x0):\n",
    "        self.position_i=[]          # particle position\n",
    "        self.velocity_i=[]          # particle velocity\n",
    "        self.pos_best_i=[]          # best position individual\n",
    "        self.err_best_i=-1          # best error individual\n",
    "        self.err_i=-1               # error individual\n",
    "\n",
    "    \n",
    "        self.velocity_i.append(random.uniform(-1,1))\n",
    "        self.position_i.append(x0)\n",
    "\n",
    "    # evaluate current fitness\n",
    "    def evaluate(self):\n",
    "    \t#self.err_i=costFunc(self.position_i)\n",
    "        #net = Net(int(round(self.position_i[0])))\n",
    "        net = WineModel(round(self.position_i[0]))\n",
    "    \t#print(net)\n",
    "        #optimizer = optim.Adam(net.parameters(), lr=0.05)\n",
    "        #def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "        #history = []\n",
    "        lr = 1e-2\n",
    "        epochs = 2000\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr)\n",
    "        for epoch in range(epochs):\n",
    "            # Training Phase \n",
    "            for batch in train_loader:\n",
    "                loss = net.training_step(batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            # Validation phase\n",
    "            result = evaluate(net, val_loader)\n",
    "            net.epoch_end(epoch, result, epochs)\n",
    "            #history.append(result)  #appends total validation loss of whole validation set epoch wise\n",
    "        self.err_i = result['val_loss']\n",
    "\n",
    "        # check to see if the current position is an individual best\n",
    "        if self.err_i < self.err_best_i or self.err_best_i==-1:\n",
    "            self.pos_best_i=self.position_i\n",
    "            self.err_best_i=self.err_i\n",
    "\n",
    "    # update new particle velocity\n",
    "    def update_velocity(self,pos_best_g):\n",
    "        w=0.5       # constant inertia weight (how much to weigh the previous velocity)\n",
    "        c1=1        # cognative constant\n",
    "        c2=2        # social constant\n",
    "\n",
    "        r1=random.random()\n",
    "        r2=random.random()\n",
    "\n",
    "        vel_cognitive=c1*r1*(self.pos_best_i[0]-self.position_i[0])\n",
    "        vel_social=c2*r2*(pos_best_g[0]-self.position_i[0])\n",
    "        self.velocity_i[0]=w*self.velocity_i[0]+vel_cognitive+vel_social\n",
    "\n",
    "    # update the particle position based off new velocity updates\n",
    "    def update_position(self,bounds):\n",
    "        self.position_i[0]=self.position_i[0]+self.velocity_i[0]\n",
    "\n",
    "        # adjust maximum position if necessary\n",
    "        if self.position_i[0]>bounds[1]:\n",
    "        \tself.position_i[0]=bounds[1]\n",
    "\n",
    "        # adjust minimum position if neseccary\n",
    "        if self.position_i[0] < bounds[0]:\n",
    "        \tself.position_i[0]=bounds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 0\n",
      "*****************************\n",
      "Particle:  0\n",
      "Epoch [100], val_loss: 0.7843\n",
      "Epoch [200], val_loss: 2.0415\n",
      "Epoch [300], val_loss: 0.9041\n",
      "Epoch [400], val_loss: 0.6717\n",
      "Epoch [500], val_loss: 0.6306\n",
      "Epoch [600], val_loss: 0.5583\n",
      "Epoch [700], val_loss: 0.6897\n",
      "Epoch [800], val_loss: 0.5611\n",
      "Epoch [900], val_loss: 0.6723\n",
      "Epoch [1000], val_loss: 0.5869\n",
      "Epoch [1100], val_loss: 0.5557\n",
      "Epoch [1200], val_loss: 1.0460\n",
      "Epoch [1300], val_loss: 0.5627\n",
      "Epoch [1400], val_loss: 0.5616\n",
      "Epoch [1500], val_loss: 0.5755\n",
      "Epoch [1600], val_loss: 0.5937\n",
      "Epoch [1700], val_loss: 0.7340\n",
      "Epoch [1800], val_loss: 0.6207\n",
      "Epoch [1900], val_loss: 0.5745\n",
      "Epoch [2000], val_loss: 0.6548\n",
      "pos_best_g so far [5]\n",
      "Particle:  1\n",
      "Epoch [100], val_loss: 1.1476\n",
      "Epoch [200], val_loss: 1.4439\n",
      "Epoch [300], val_loss: 0.5809\n",
      "Epoch [400], val_loss: 0.6698\n",
      "Epoch [500], val_loss: 0.5616\n",
      "Epoch [600], val_loss: 0.6866\n",
      "Epoch [700], val_loss: 0.6145\n",
      "Epoch [800], val_loss: 0.5775\n",
      "Epoch [900], val_loss: 0.6169\n",
      "Epoch [1000], val_loss: 0.6114\n",
      "Epoch [1100], val_loss: 0.5877\n",
      "Epoch [1200], val_loss: 0.5980\n",
      "Epoch [1300], val_loss: 0.7045\n",
      "Epoch [1400], val_loss: 0.5515\n",
      "Epoch [1500], val_loss: 0.6828\n",
      "Epoch [1600], val_loss: 0.6258\n",
      "Epoch [1700], val_loss: 0.8200\n",
      "Epoch [1800], val_loss: 0.6071\n",
      "Epoch [1900], val_loss: 0.6847\n",
      "Epoch [2000], val_loss: 0.5407\n",
      "pos_best_g so far [5]\n",
      "Particle:  2\n",
      "Epoch [100], val_loss: 1.9071\n",
      "Epoch [200], val_loss: 0.6081\n",
      "Epoch [300], val_loss: 1.1964\n",
      "Epoch [400], val_loss: 0.6765\n",
      "Epoch [500], val_loss: 0.5641\n",
      "Epoch [600], val_loss: 0.6073\n",
      "Epoch [700], val_loss: 0.6582\n",
      "Epoch [800], val_loss: 0.5651\n",
      "Epoch [900], val_loss: 0.6282\n",
      "Epoch [1000], val_loss: 0.5810\n",
      "Epoch [1100], val_loss: 0.5555\n",
      "Epoch [1200], val_loss: 0.6040\n",
      "Epoch [1300], val_loss: 0.5682\n",
      "Epoch [1400], val_loss: 0.6831\n",
      "Epoch [1500], val_loss: 0.6295\n",
      "Epoch [1600], val_loss: 0.5620\n",
      "Epoch [1700], val_loss: 0.5471\n",
      "Epoch [1800], val_loss: 0.5687\n",
      "Epoch [1900], val_loss: 0.5405\n",
      "Epoch [2000], val_loss: 0.5596\n",
      "pos_best_g so far [5]\n",
      "Iteration : 1\n",
      "*****************************\n",
      "Particle:  0\n",
      "Epoch [100], val_loss: 2.8550\n",
      "Epoch [200], val_loss: 1.6357\n",
      "Epoch [300], val_loss: 0.9981\n",
      "Epoch [400], val_loss: 0.9130\n",
      "Epoch [500], val_loss: 0.6050\n",
      "Epoch [600], val_loss: 0.6630\n",
      "Epoch [700], val_loss: 0.7094\n",
      "Epoch [800], val_loss: 0.6136\n",
      "Epoch [900], val_loss: 0.5600\n",
      "Epoch [1000], val_loss: 0.6353\n",
      "Epoch [1100], val_loss: 0.8262\n",
      "Epoch [1200], val_loss: 0.5825\n",
      "Epoch [1300], val_loss: 0.8034\n",
      "Epoch [1400], val_loss: 0.7260\n",
      "Epoch [1500], val_loss: 0.9711\n",
      "Epoch [1600], val_loss: 0.5868\n",
      "Epoch [1700], val_loss: 0.5414\n",
      "Epoch [1800], val_loss: 0.6038\n",
      "Epoch [1900], val_loss: 0.5646\n",
      "Epoch [2000], val_loss: 0.6118\n",
      "pos_best_g so far [5]\n",
      "Particle:  1\n",
      "Epoch [100], val_loss: 1.7898\n",
      "Epoch [200], val_loss: 0.7217\n",
      "Epoch [300], val_loss: 0.6522\n",
      "Epoch [400], val_loss: 1.0381\n",
      "Epoch [500], val_loss: 0.5914\n",
      "Epoch [600], val_loss: 0.8655\n",
      "Epoch [700], val_loss: 0.5775\n",
      "Epoch [800], val_loss: 0.6798\n",
      "Epoch [900], val_loss: 0.6291\n",
      "Epoch [1000], val_loss: 0.5632\n",
      "Epoch [1100], val_loss: 0.5930\n",
      "Epoch [1200], val_loss: 0.5701\n",
      "Epoch [1300], val_loss: 0.5972\n",
      "Epoch [1400], val_loss: 0.6312\n",
      "Epoch [1500], val_loss: 0.6401\n",
      "Epoch [1600], val_loss: 0.5914\n",
      "Epoch [1700], val_loss: 0.7604\n",
      "Epoch [1800], val_loss: 0.5551\n",
      "Epoch [1900], val_loss: 0.6492\n",
      "Epoch [2000], val_loss: 0.6885\n",
      "pos_best_g so far [5]\n",
      "Particle:  2\n",
      "Epoch [100], val_loss: 1.2988\n",
      "Epoch [200], val_loss: 1.1683\n",
      "Epoch [300], val_loss: 0.5962\n",
      "Epoch [400], val_loss: 0.5774\n",
      "Epoch [500], val_loss: 0.6195\n",
      "Epoch [600], val_loss: 0.6908\n",
      "Epoch [700], val_loss: 0.6413\n",
      "Epoch [800], val_loss: 0.6239\n",
      "Epoch [900], val_loss: 0.6361\n",
      "Epoch [1000], val_loss: 0.5730\n",
      "Epoch [1100], val_loss: 0.6033\n",
      "Epoch [1200], val_loss: 0.5649\n",
      "Epoch [1300], val_loss: 0.6391\n",
      "Epoch [1400], val_loss: 0.5634\n",
      "Epoch [1500], val_loss: 0.5711\n",
      "Epoch [1600], val_loss: 0.5747\n",
      "Epoch [1700], val_loss: 0.5609\n",
      "Epoch [1800], val_loss: 0.6881\n",
      "Epoch [1900], val_loss: 0.6030\n",
      "Epoch [2000], val_loss: 0.5656\n",
      "pos_best_g so far [5]\n",
      "Iteration : 2\n",
      "*****************************\n",
      "Particle:  0\n",
      "Epoch [100], val_loss: 1.4609\n",
      "Epoch [200], val_loss: 1.1991\n",
      "Epoch [300], val_loss: 1.0349\n",
      "Epoch [400], val_loss: 0.7987\n",
      "Epoch [500], val_loss: 0.9314\n",
      "Epoch [600], val_loss: 0.5591\n",
      "Epoch [700], val_loss: 0.5972\n",
      "Epoch [800], val_loss: 0.5985\n",
      "Epoch [900], val_loss: 0.5919\n",
      "Epoch [1000], val_loss: 0.6215\n",
      "Epoch [1100], val_loss: 0.6199\n",
      "Epoch [1200], val_loss: 0.5883\n",
      "Epoch [1300], val_loss: 0.5672\n",
      "Epoch [1400], val_loss: 0.5625\n",
      "Epoch [1500], val_loss: 0.6037\n",
      "Epoch [1600], val_loss: 0.6493\n",
      "Epoch [1700], val_loss: 0.5534\n",
      "Epoch [1800], val_loss: 0.5708\n",
      "Epoch [1900], val_loss: 0.5753\n",
      "Epoch [2000], val_loss: 0.5425\n",
      "pos_best_g so far [5]\n",
      "Particle:  1\n",
      "Epoch [100], val_loss: 1.0991\n",
      "Epoch [200], val_loss: 1.7409\n",
      "Epoch [300], val_loss: 0.6917\n",
      "Epoch [400], val_loss: 0.7751\n",
      "Epoch [500], val_loss: 0.6848\n",
      "Epoch [600], val_loss: 0.6229\n",
      "Epoch [700], val_loss: 0.5786\n",
      "Epoch [800], val_loss: 0.6025\n",
      "Epoch [900], val_loss: 0.7645\n",
      "Epoch [1000], val_loss: 0.5656\n",
      "Epoch [1100], val_loss: 0.6535\n",
      "Epoch [1200], val_loss: 0.5960\n",
      "Epoch [1300], val_loss: 0.6288\n",
      "Epoch [1400], val_loss: 0.5755\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "class PSO():\n",
    "    def __init__(self,x0,bounds,num_particles,maxiter):\n",
    "        global num_dimensions\n",
    "\n",
    "        num_dimensions= 1\n",
    "        err_best_g=-1                   # best error for group\n",
    "        pos_best_g=[]                   # best position for group\n",
    "\n",
    "        # establish the swarm\n",
    "        swarm=[]\n",
    "        for i in range(0,num_particles):\n",
    "            swarm.append(Particle(x0))\n",
    "        #print('Swarm : ',swarm)\n",
    "\n",
    "        # begin optimization loop\n",
    "        i=0\n",
    "        while i < maxiter:\n",
    "            print('Iteration :', i)\n",
    "            print('*****************************')\n",
    "            #print i,err_best_g\n",
    "            # cycle through particles in swarm and evaluate fitness\n",
    "            for j in range(0,num_particles):\n",
    "                print('Particle: ',j)\n",
    "                swarm[j].evaluate()\n",
    "                #print('swarm[{}].evaluate = {}'.format(j, swarm[j].evaluate(costFunc)))\n",
    "\n",
    "                # determine if current particle is the best (globally)\n",
    "                if swarm[j].err_i < err_best_g or err_best_g == -1:\n",
    "                    pos_best_g=list(swarm[j].position_i)\n",
    "                    err_best_g=float(swarm[j].err_i)\n",
    "                print('pos_best_g so far', pos_best_g)\n",
    "\n",
    "            # cycle through swarm and update velocities and position\n",
    "            for j in range(0,num_particles):\n",
    "                swarm[j].update_velocity(pos_best_g)\n",
    "                swarm[j].update_position(bounds)\n",
    "            i+=1\n",
    "\n",
    "        # print final results\n",
    "        print('FINAL:')\n",
    "        print(pos_best_g)\n",
    "        print(err_best_g)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "#--- RUN ----------------------------------------------------------------------+\n",
    "\n",
    "    initial = 5               # initial starting location [x1,x2...]\n",
    "    bounds=[1,10]  # input bounds [(x1_min,x1_max),(x2_min,x2_max)...]\n",
    "    PSO(initial,bounds,num_particles=3,maxiter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bitee90aa3ac2fb4953b8d17317969debac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
