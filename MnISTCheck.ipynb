{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n",
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([7, 3, 8, 0, 9, 1, 5, 2, 3, 9])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "train = datasets.MNIST(\"\", train=True, download=True, transform = transforms.Compose([transforms.ToTensor()]))\n",
    "test = datasets.MNIST(\"\", train=False, download=True, transform = transforms.Compose([transforms.ToTensor()]))\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)\n",
    "total = 0\n",
    "counter_dict = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0 }\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "print(counter_dict)\n",
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100}\")\n",
    "\n",
    "for data in trainset:\n",
    "    print(data)\n",
    "    break\n",
    "x, y = data[0][0], data[1][0]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data[0][0].view(28,28))\n",
    "plt.show()\n",
    "print(data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, number_of_neurons):    \n",
    "        print('inside net!')\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, number_of_neurons)\n",
    "        self.fc2 = nn.Linear(number_of_neurons, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self,x0):\n",
    "        self.position_i=[]          # particle position\n",
    "        self.velocity_i=[]          # particle velocity\n",
    "        self.pos_best_i=[]          # best position individual\n",
    "        self.err_best_i=-1          # best error individual\n",
    "        self.err_i=-1               # error individual\n",
    "\n",
    "    \n",
    "        self.velocity_i.append(random.uniform(-1,1))\n",
    "        self.position_i.append(x0)\n",
    "\n",
    "    # evaluate current fitness\n",
    "    def evaluate(self):\n",
    "    \t#self.err_i=costFunc(self.position_i)\n",
    "        net = Net(int(round(self.position_i[0])))\n",
    "    \t#print(net)\n",
    "        optimizer = optim.Adam(net.parameters(), lr=0.05)\n",
    "\n",
    "\n",
    "        for epoch in range(3):\n",
    "            for data in trainset:\n",
    "                X, y = data\n",
    "                net.zero_grad()\n",
    "                output =  net(X.view(-1, 28*28))\n",
    "                loss = F.nll_loss(output, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            print('Loss',loss)\n",
    "            print('Epoch', epoch)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in trainset:\n",
    "                X, y = data\n",
    "                output = net(X.view(-1, 784))\n",
    "                for idx, i in enumerate(output):\n",
    "                    if torch.argmax(i) == y[idx]:\n",
    "                        correct += 1\n",
    "                    total += 1\n",
    "        print(\"Accuracy\", round(correct/total, 3))\n",
    "        self.err_i = loss\n",
    "\n",
    "        # check to see if the current position is an individual best\n",
    "        if self.err_i < self.err_best_i or self.err_best_i==-1:\n",
    "            self.pos_best_i=self.position_i\n",
    "            self.err_best_i=self.err_i\n",
    "\n",
    "    # update new particle velocity\n",
    "    def update_velocity(self,pos_best_g):\n",
    "        w=0.5       # constant inertia weight (how much to weigh the previous velocity)\n",
    "        c1=1        # cognative constant\n",
    "        c2=2        # social constant\n",
    "\n",
    "        r1=random.random()\n",
    "        r2=random.random()\n",
    "\n",
    "        vel_cognitive=c1*r1*(self.pos_best_i[0]-self.position_i[0])\n",
    "        vel_social=c2*r2*(pos_best_g[0]-self.position_i[0])\n",
    "        self.velocity_i[0]=w*self.velocity_i[0]+vel_cognitive+vel_social\n",
    "\n",
    "    # update the particle position based off new velocity updates\n",
    "    def update_position(self,bounds):\n",
    "        self.position_i[0]=self.position_i[0]+self.velocity_i[0]\n",
    "\n",
    "        # adjust maximum position if necessary\n",
    "        if self.position_i[0]>bounds[1]:\n",
    "        \tself.position_i[0]=bounds[1]\n",
    "\n",
    "        # adjust minimum position if neseccary\n",
    "        if self.position_i[0] < bounds[0]:\n",
    "        \tself.position_i[0]=bounds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 0\n",
      "*****************************\n",
      "inside net!\n",
      "Loss tensor(1.1860, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.0760, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.0551, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.434\n",
      "0\n",
      "pos_best_g  [3]\n",
      "inside net!\n",
      "Loss tensor(1.9494, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.1242, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.0360, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.252\n",
      "1\n",
      "inside net!\n",
      "Loss tensor(1.5278, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.9347, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.2146, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.402\n",
      "2\n",
      "inside net!\n",
      "Loss tensor(2.0878, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.0041, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.6378, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.293\n",
      "3\n",
      "inside net!\n",
      "Loss tensor(0.6952, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(0.5256, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.4137, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.432\n",
      "4\n",
      "inside net!\n",
      "Loss tensor(2.1187, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.5105, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.8704, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.343\n",
      "5\n",
      "inside net!\n",
      "Loss tensor(1.9802, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.9320, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.0101, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.201\n",
      "6\n",
      "inside net!\n",
      "Loss tensor(1.6574, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.6434, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(0.8402, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.36\n",
      "7\n",
      "pos_best_g  [3]\n",
      "Iteration : 1\n",
      "*****************************\n",
      "inside net!\n",
      "Loss tensor(2.3295, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.2930, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.3279, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.099\n",
      "0\n",
      "inside net!\n",
      "Loss tensor(1.4038, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.5836, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.4120, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.353\n",
      "1\n",
      "inside net!\n",
      "Loss tensor(2.0936, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.9070, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.4477, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.269\n",
      "2\n",
      "inside net!\n",
      "Loss tensor(2.2455, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.2270, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.0817, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.204\n",
      "3\n",
      "inside net!\n",
      "Loss tensor(2.8738, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.1035, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.8458, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.411\n",
      "4\n",
      "inside net!\n",
      "Loss tensor(2.3661, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.3376, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.3076, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.112\n",
      "5\n",
      "inside net!\n",
      "Loss tensor(1.4121, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.7485, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.6804, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.295\n",
      "6\n",
      "inside net!\n",
      "Loss tensor(1.7368, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.2076, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.1576, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.18\n",
      "7\n",
      "Iteration : 2\n",
      "*****************************\n",
      "inside net!\n",
      "Loss tensor(1.3552, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.1306, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.7419, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.24\n",
      "0\n",
      "inside net!\n",
      "Loss tensor(1.7714, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.3251, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.2325, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.349\n",
      "1\n",
      "inside net!\n",
      "Loss tensor(2.2791, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.1435, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.3770, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.262\n",
      "2\n",
      "inside net!\n",
      "Loss tensor(1.4215, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.1328, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.7265, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.352\n",
      "3\n",
      "inside net!\n",
      "Loss tensor(1.8316, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.2238, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.1864, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.191\n",
      "4\n",
      "inside net!\n",
      "Loss tensor(1.4076, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.7245, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.5649, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.261\n",
      "5\n",
      "inside net!\n",
      "Loss tensor(1.9622, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.6710, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.4840, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.366\n",
      "6\n",
      "inside net!\n",
      "Loss tensor(1.9237, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.6296, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.4812, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.325\n",
      "7\n",
      "Iteration : 3\n",
      "*****************************\n",
      "inside net!\n",
      "Loss tensor(1.6723, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.5961, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.9920, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.345\n",
      "0\n",
      "inside net!\n",
      "Loss tensor(1.5878, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.8007, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.0893, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.175\n",
      "1\n",
      "inside net!\n",
      "Loss tensor(2.0497, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.4815, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.2433, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.193\n",
      "2\n",
      "inside net!\n",
      "Loss tensor(2.0353, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.3873, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.6991, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.329\n",
      "3\n",
      "inside net!\n",
      "Loss tensor(2.1088, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.6264, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.9135, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.273\n",
      "4\n",
      "inside net!\n",
      "Loss tensor(2.0178, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(0.9454, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.6528, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.377\n",
      "5\n",
      "inside net!\n",
      "Loss tensor(2.2397, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.3637, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.3106, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.099\n",
      "6\n",
      "inside net!\n",
      "Loss tensor(2.2444, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.1030, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.9814, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.187\n",
      "7\n",
      "Iteration : 4\n",
      "*****************************\n",
      "inside net!\n",
      "Loss tensor(1.9041, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.2952, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.8226, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.294\n",
      "0\n",
      "inside net!\n",
      "Loss tensor(2.0075, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.0224, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.0528, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.183\n",
      "1\n",
      "inside net!\n",
      "Loss tensor(1.9315, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.2768, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.9937, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.253\n",
      "2\n",
      "inside net!\n",
      "Loss tensor(2.0695, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.6025, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.9485, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.236\n",
      "3\n",
      "inside net!\n",
      "Loss tensor(1.8371, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.0005, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.8360, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.201\n",
      "4\n",
      "inside net!\n",
      "Loss tensor(1.7469, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.1468, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.1608, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.289\n",
      "5\n",
      "inside net!\n",
      "Loss tensor(1.9226, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.0721, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.5715, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.293\n",
      "6\n",
      "inside net!\n",
      "Loss tensor(1.4291, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.9331, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.3555, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.436\n",
      "7\n",
      "Iteration : 5\n",
      "*****************************\n",
      "inside net!\n",
      "Loss tensor(1.1374, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.7988, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.1325, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.406\n",
      "0\n",
      "inside net!\n",
      "Loss tensor(1.9623, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.8001, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.2044, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.196\n",
      "1\n",
      "inside net!\n",
      "Loss tensor(1.2291, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.1800, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.0888, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.362\n",
      "2\n",
      "inside net!\n",
      "Loss tensor(1.6405, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.3109, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.1289, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.33\n",
      "3\n",
      "inside net!\n",
      "Loss tensor(1.2894, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.6090, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.7010, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.417\n",
      "4\n",
      "inside net!\n",
      "Loss tensor(2.2832, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.2494, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.3790, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.099\n",
      "5\n",
      "inside net!\n",
      "Loss tensor(2.0142, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.4590, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.1029, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.262\n",
      "6\n",
      "inside net!\n",
      "Loss tensor(1.6714, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.3651, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.4262, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.406\n",
      "7\n",
      "Iteration : 6\n",
      "*****************************\n",
      "inside net!\n",
      "Loss tensor(2.2724, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.0814, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.7399, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.176\n",
      "0\n",
      "inside net!\n",
      "Loss tensor(1.9738, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.9993, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.7843, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.204\n",
      "1\n",
      "inside net!\n",
      "Loss tensor(1.1852, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(3.7856, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.0115, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.365\n",
      "2\n",
      "inside net!\n",
      "Loss tensor(2.0694, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.2236, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.1173, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.199\n",
      "3\n",
      "inside net!\n",
      "Loss tensor(2.3763, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.2800, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.2379, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.102\n",
      "4\n",
      "inside net!\n",
      "Loss tensor(1.9811, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.2036, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.2482, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.185\n",
      "5\n",
      "inside net!\n",
      "Loss tensor(1.9640, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.5027, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.8055, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.277\n",
      "6\n",
      "inside net!\n",
      "Loss tensor(2.0146, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.8902, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.1460, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.179\n",
      "7\n",
      "Iteration : 7\n",
      "*****************************\n",
      "inside net!\n",
      "Loss tensor(1.0569, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.2367, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(0.8639, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.435\n",
      "0\n",
      "inside net!\n",
      "Loss tensor(2.3705, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.4079, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.2550, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.099\n",
      "1\n",
      "inside net!\n",
      "Loss tensor(1.8343, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.8339, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.3621, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.358\n",
      "2\n",
      "inside net!\n",
      "Loss tensor(1.8469, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.8222, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.3368, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.204\n",
      "3\n",
      "inside net!\n",
      "Loss tensor(1.5367, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.6045, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.6216, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.318\n",
      "4\n",
      "inside net!\n",
      "Loss tensor(2.2463, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.6173, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.4516, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.226\n",
      "5\n",
      "inside net!\n",
      "Loss tensor(1.7049, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.8244, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.0248, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.266\n",
      "6\n",
      "inside net!\n",
      "Loss tensor(1.5340, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.1750, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.0538, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.204\n",
      "7\n",
      "Iteration : 8\n",
      "*****************************\n",
      "inside net!\n",
      "Loss tensor(2.0142, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.3783, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.1916, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.203\n",
      "0\n",
      "inside net!\n",
      "Loss tensor(1.9744, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.4037, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.4626, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.241\n",
      "1\n",
      "inside net!\n",
      "Loss tensor(2.4095, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.0255, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.2270, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.173\n",
      "2\n",
      "inside net!\n",
      "Loss tensor(2.2547, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.8467, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.5009, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.295\n",
      "3\n",
      "inside net!\n",
      "Loss tensor(2.3121, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.0042, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.2019, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.161\n",
      "4\n",
      "inside net!\n",
      "Loss tensor(1.7440, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.4718, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.6766, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.277\n",
      "5\n",
      "inside net!\n",
      "Loss tensor(1.7161, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.0495, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.8697, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.337\n",
      "6\n",
      "inside net!\n",
      "Loss tensor(1.8217, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.1873, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.5019, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.204\n",
      "7\n",
      "Iteration : 9\n",
      "*****************************\n",
      "inside net!\n",
      "Loss tensor(1.9128, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.1908, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.6781, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.415\n",
      "0\n",
      "inside net!\n",
      "Loss tensor(1.9870, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.1899, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.2476, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.194\n",
      "1\n",
      "inside net!\n",
      "Loss tensor(2.1235, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.9976, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.0443, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.212\n",
      "2\n",
      "inside net!\n",
      "Loss tensor(2.2070, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.0222, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(2.2356, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.203\n",
      "3\n",
      "inside net!\n",
      "Loss tensor(1.7149, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.2482, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.6052, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.266\n",
      "4\n",
      "inside net!\n",
      "Loss tensor(1.7702, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.9181, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.7621, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.272\n",
      "5\n",
      "inside net!\n",
      "Loss tensor(1.2877, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(1.6066, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.7861, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.428\n",
      "6\n",
      "inside net!\n",
      "Loss tensor(2.1291, grad_fn=<NllLossBackward>)\n",
      "Epoch 0\n",
      "Loss tensor(2.2805, grad_fn=<NllLossBackward>)\n",
      "Epoch 1\n",
      "Loss tensor(1.7156, grad_fn=<NllLossBackward>)\n",
      "Epoch 2\n",
      "Accuracy 0.196\n",
      "7\n",
      "FINAL:\n",
      "[3]\n",
      "0.8402248620986938\n"
     ]
    }
   ],
   "source": [
    "class PSO():\n",
    "    def __init__(self,x0,bounds,num_particles,maxiter):\n",
    "        global num_dimensions\n",
    "\n",
    "        num_dimensions= 1\n",
    "        err_best_g=-1                   # best error for group\n",
    "        pos_best_g=[]                   # best position for group\n",
    "\n",
    "        # establish the swarm\n",
    "        swarm=[]\n",
    "        for i in range(0,num_particles):\n",
    "            swarm.append(Particle(x0))\n",
    "        #print('Swarm : ',swarm)\n",
    "\n",
    "        # begin optimization loop\n",
    "        i=0\n",
    "        while i < maxiter:\n",
    "            print('Iteration :', i)\n",
    "            print('*****************************')\n",
    "            #print i,err_best_g\n",
    "            # cycle through particles in swarm and evaluate fitness\n",
    "            for j in range(0,num_particles):\n",
    "                swarm[j].evaluate()\n",
    "                print(j)\n",
    "                #print('swarm[{}].evaluate = {}'.format(j, swarm[j].evaluate(costFunc)))\n",
    "\n",
    "                # determine if current particle is the best (globally)\n",
    "                if swarm[j].err_i < err_best_g or err_best_g == -1:\n",
    "                    pos_best_g=list(swarm[j].position_i)\n",
    "                    err_best_g=float(swarm[j].err_i)\n",
    "                    print('pos_best_g ', pos_best_g)\n",
    "\n",
    "            # cycle through swarm and update velocities and position\n",
    "            for j in range(0,num_particles):\n",
    "                swarm[j].update_velocity(pos_best_g)\n",
    "                swarm[j].update_position(bounds)\n",
    "            i+=1\n",
    "\n",
    "        # print final results\n",
    "        print('FINAL:')\n",
    "        print(pos_best_g)\n",
    "        print(err_best_g)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "#--- RUN ----------------------------------------------------------------------+\n",
    "\n",
    "    initial= 3               # initial starting location [x1,x2...]\n",
    "    bounds=[1,10]  # input bounds [(x1_min,x1_max),(x2_min,x2_max)...]\n",
    "    PSO(initial,bounds,num_particles=8,maxiter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bitee90aa3ac2fb4953b8d17317969debac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
