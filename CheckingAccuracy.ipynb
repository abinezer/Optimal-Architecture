{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>l3</th>\n",
       "      <th>l4</th>\n",
       "      <th>l5</th>\n",
       "      <th>l6</th>\n",
       "      <th>l7</th>\n",
       "      <th>l8</th>\n",
       "      <th>l9</th>\n",
       "      <th>l10</th>\n",
       "      <th>l11</th>\n",
       "      <th>l12</th>\n",
       "      <th>l13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   output     l1    l2    l3    l4   l5    l6    l7    l8    l9   l10   l11  \\\n",
       "0       1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04   \n",
       "1       1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05   \n",
       "2       1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03   \n",
       "3       1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86   \n",
       "4       1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04   \n",
       "\n",
       "    l12   l13  \n",
       "0  3.92  1065  \n",
       "1  3.40  1050  \n",
       "2  3.17  1185  \n",
       "3  3.45  1480  \n",
       "4  2.93   735  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/abishai/Documents/ANN_Research/bio/WaterCycle/wine.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df2 = pd.DataFrame(x_scaled)\n",
    "df2.head()\n",
    "df = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_cols = list(df.columns)[1:]\n",
    "input_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_cols = [0]\n",
    "output_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    178.000000\n",
       "mean       0.469101\n",
       "std        0.387517\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.500000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_arrays(df):\n",
    "    # Make a copy of the original dataframe\n",
    "    df1 = df.copy(deep=True)\n",
    "    # Extract input & outupts as numpy arrays\n",
    "    inputs_array = df1[input_cols].to_numpy()\n",
    "    targets_array = df1[output_cols].to_numpy()\n",
    "    return inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.84210526, 0.1916996 , 0.57219251, ..., 0.45528455, 0.97069597,\n",
       "         0.56134094],\n",
       "        [0.57105263, 0.2055336 , 0.4171123 , ..., 0.46341463, 0.78021978,\n",
       "         0.55064194],\n",
       "        [0.56052632, 0.3201581 , 0.70053476, ..., 0.44715447, 0.6959707 ,\n",
       "         0.64693295],\n",
       "        ...,\n",
       "        [0.58947368, 0.69960474, 0.48128342, ..., 0.08943089, 0.10622711,\n",
       "         0.39728959],\n",
       "        [0.56315789, 0.36561265, 0.54010695, ..., 0.09756098, 0.12820513,\n",
       "         0.40085592],\n",
       "        [0.81578947, 0.66403162, 0.73796791, ..., 0.10569106, 0.12087912,\n",
       "         0.20114123]]),\n",
       " array([[0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_array, targets_array = dataframe_to_arrays(df)\n",
    "inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "inputs = torch.Tensor(inputs_array)\n",
    "targets = torch.Tensor(targets_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "dataset = TensorDataset(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = len(df)\n",
    "val_percent = 0.1 # between 0.1 and 0.2\n",
    "val_size = int(num_rows * val_percent)\n",
    "train_size = num_rows - val_size\n",
    "\n",
    "\n",
    "train_df, val_df = random_split(dataset, [train_size, val_size]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_df, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_df, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "input_size = len(input_cols)\n",
    "output_size = 1\n",
    "print(input_size)\n",
    "print(output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class WineModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()     \n",
    "        self.fc1 = nn.Linear(input_size, 10)\n",
    "        self.fc2 = nn.Linear(10,output_size)\n",
    "        # fill this (hint: use input_size & output_size defined above)\n",
    "        #model initialized with random weight\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = F.relu(self.fc1(xb))\n",
    "        out = self.fc2(xb)             # batch wise forwarding\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch \n",
    "        # Generate predictions\n",
    "        out = self(inputs)         \n",
    "        # Calcuate loss\n",
    "        loss = F.l1_loss(out, targets)  # batch wise training step and loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        # Generate predictions\n",
    "        out = self(inputs)\n",
    "        # Calculate loss\n",
    "        loss =F.l1_loss(out, targets)       # batch wise validation and loss    \n",
    "        return {'val_loss': loss.detach()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine val losses of all batches as average\n",
    "        return {'val_loss': epoch_loss.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result, num_epochs):\n",
    "        # Print result every 20th epoch\n",
    "        if (epoch+1) % 500 == 0 or epoch == num_epochs-1:\n",
    "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate2(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    lr,\n",
    "    model,\n",
    "    train_loader,\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate2(model, val_loader)\n",
    "        model.epoch_end(epoch, result, epochs)\n",
    "        history.append(result)  #appends total validation loss of whole validation set epoch wise\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 0.8849727511405945}\n"
     ]
    }
   ],
   "source": [
    "model =  WineModel()\n",
    "result = evaluate2(model,val_loader) # Use the the evaluate function\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(input, target, model):\n",
    "    inputs = input.unsqueeze(0) \n",
    "    predictions = model(inputs)\n",
    "    prediction = predictions[0].detach()\n",
    "    print(\"Input:\", input)\n",
    "    print(\"Target:\", target)\n",
    "    print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([0.6211, 0.2036, 0.6738, 0.2835, 0.2500, 0.6448, 0.5485, 0.3962, 0.3281,\n",
      "        0.3003, 0.3577, 0.7143, 0.6541])\n",
      "Target: tensor([0.])\n",
      "Prediction: tensor([-0.3783])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_df[0]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500], val_loss: 0.1126\n",
      "Epoch [1000], val_loss: 0.0912\n",
      "Epoch [1500], val_loss: 0.0875\n",
      "Epoch [2000], val_loss: 0.0866\n",
      "Epoch [2500], val_loss: 0.0814\n",
      "Epoch [3000], val_loss: 0.0768\n",
      "Epoch [3500], val_loss: 0.0703\n",
      "Epoch [4000], val_loss: 0.0619\n",
      "Epoch [4500], val_loss: 0.0556\n",
      "Epoch [5000], val_loss: 0.0591\n",
      "Epoch [5500], val_loss: 0.0603\n",
      "Epoch [6000], val_loss: 0.0580\n",
      "Epoch [6500], val_loss: 0.0710\n",
      "Epoch [7000], val_loss: 0.0672\n",
      "Epoch [7500], val_loss: 0.0701\n",
      "Epoch [8000], val_loss: 0.0603\n",
      "Epoch [8500], val_loss: 0.0637\n",
      "Epoch [9000], val_loss: 0.0693\n"
     ]
    }
   ],
   "source": [
    "epochs = 9000\n",
    "lr = 1e-2\n",
    "history5 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([0.4395, 0.5553, 0.5348, 0.5619, 0.3913, 0.2483, 0.1814, 0.0755, 0.1356,\n",
      "        0.3174, 0.2439, 0.0073, 0.2297])\n",
      "Target: tensor([1.])\n",
      "Prediction: tensor([0.8687])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_df[1]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_right(input, target, model):\n",
    "    inputs = input.unsqueeze(0)\n",
    "    predictions = model(inputs)#???                # fill this\n",
    "    prediction = predictions[0].detach()\n",
    "    if abs(prediction - target) < 0.25:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(0,len(val_df)):\n",
    "    input, target = val_df[i]\n",
    "    results.append(predict_right(input, target, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in results:\n",
    "    if i == 1:\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/len(val_df)#accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('val_loss vs. No. of epochs');\n",
    "loss_mat = [res['val_loss'] for res in [result] + history5]\n",
    "plt.plot(loss_mat, '-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('val_loss')\n",
    "\n",
    "val_loss = loss_mat[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bitee90aa3ac2fb4953b8d17317969debac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
